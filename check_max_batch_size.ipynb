{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from rl_training import QLearningAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 17, 16, 5])\n",
      "Batch size 32 passed!\n",
      "torch.Size([64, 17, 16, 5])\n",
      "Batch size 64 passed!\n",
      "torch.Size([96, 17, 16, 5])\n",
      "Batch size 96 passed!\n",
      "torch.Size([128, 17, 16, 5])\n",
      "Batch size 128 passed!\n",
      "torch.Size([160, 17, 16, 5])\n",
      "Batch size 160 passed!\n",
      "torch.Size([192, 17, 16, 5])\n",
      "Batch size 192 passed!\n",
      "torch.Size([224, 17, 16, 5])\n",
      "Batch size 224 passed!\n",
      "torch.Size([256, 17, 16, 5])\n",
      "Batch size 256 passed!\n",
      "torch.Size([288, 17, 16, 5])\n",
      "Batch size 288 passed!\n",
      "torch.Size([320, 17, 16, 5])\n",
      "Batch size 320 passed!\n",
      "torch.Size([352, 17, 16, 5])\n",
      "Batch size 352 passed!\n",
      "torch.Size([384, 17, 16, 5])\n",
      "Batch size 384 passed!\n",
      "torch.Size([416, 17, 16, 5])\n",
      "Batch size 416 passed!\n",
      "torch.Size([448, 17, 16, 5])\n",
      "Batch size 448 passed!\n",
      "torch.Size([480, 17, 16, 5])\n",
      "Batch size 480 passed!\n",
      "torch.Size([512, 17, 16, 5])\n",
      "Batch size 512 passed!\n",
      "torch.Size([544, 17, 16, 5])\n",
      "Batch size 544 passed!\n",
      "torch.Size([576, 17, 16, 5])\n",
      "Batch size 576 passed!\n",
      "torch.Size([608, 17, 16, 5])\n",
      "Batch size 608 passed!\n",
      "torch.Size([640, 17, 16, 5])\n",
      "Batch size 640 passed!\n",
      "torch.Size([672, 17, 16, 5])\n",
      "Batch size 672 passed!\n",
      "torch.Size([704, 17, 16, 5])\n",
      "Batch size 704 passed!\n",
      "torch.Size([736, 17, 16, 5])\n",
      "Batch size 736 passed!\n",
      "torch.Size([768, 17, 16, 5])\n",
      "Batch size 768 passed!\n",
      "torch.Size([800, 17, 16, 5])\n",
      "Batch size 800 passed!\n",
      "torch.Size([832, 17, 16, 5])\n",
      "Batch size 832 passed!\n",
      "torch.Size([864, 17, 16, 5])\n",
      "Batch size 864 passed!\n",
      "torch.Size([896, 17, 16, 5])\n",
      "Batch size 896 passed!\n",
      "torch.Size([928, 17, 16, 5])\n",
      "Batch size 928 passed!\n",
      "torch.Size([960, 17, 16, 5])\n",
      "Batch size 960 passed!\n",
      "torch.Size([992, 17, 16, 5])\n",
      "Batch size 992 passed!\n",
      "torch.Size([1024, 17, 16, 5])\n",
      "Batch size 1024 passed!\n",
      "Maximum batch size that fits in memory: 1024\n"
     ]
    }
   ],
   "source": [
    "def test_batch_size(model, input_shape, max_batch_size=1024, step=32):\n",
    "    \"\"\"\n",
    "    Tests the maximum batch size that will fit in memory.\n",
    "    \n",
    "    :param model: Model for testing.\n",
    "    :param input_shape: Input tensor size without considering the batch size.\n",
    "    :param max_batch_size: Maximum batch size for testing.\n",
    "    :param step: Step for increasing the batch size.\n",
    "    :return: Maximum batch size that fits in memory.\n",
    "    \"\"\"\n",
    "    model.eval()  # Switch the model to evaluation mode\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch_size in range(step, max_batch_size + step, step):\n",
    "            try:\n",
    "                # Create a random input tensor\n",
    "                input_tensor = torch.randn((batch_size, *input_shape)).to('cuda')\n",
    "                print(input_tensor.shape)\n",
    "                \n",
    "                # Pass the tensor through the model\n",
    "                _ = model(input_tensor)\n",
    "                \n",
    "                print(f\"Batch size {batch_size} passed!\")\n",
    "            except RuntimeError as e:\n",
    "                if 'out of memory' in str(e):\n",
    "                    print(f\"Batch size {batch_size} caused out of memory error!\")\n",
    "                    return batch_size - step\n",
    "                else:\n",
    "                    raise e\n",
    "    return max_batch_size\n",
    "\n",
    "# Usage example:\n",
    "ai = QLearningAI(None, None)  # Initialize your QLearningAI class\n",
    "ai.init(-1, None, None)  # Initialize the model\n",
    "max_batch = test_batch_size(ai.online_model, (17, 16, 5))\n",
    "print(f\"Maximum batch size that fits in memory: {max_batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 17, 16, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sample tensor\n",
    "tensor = torch.rand((20, 17, 16, 5))\n",
    "\n",
    "# Horizontal flip\n",
    "horizontal_flipped = torch.flip(tensor, [3])\n",
    "\n",
    "# Vertical flip\n",
    "vertical_flipped = torch.flip(tensor, [2])\n",
    "\n",
    "# Stack original tensor with the flipped tensors along the batch dimension\n",
    "augmented_tensor = torch.cat((tensor, horizontal_flipped, vertical_flipped), 0)\n",
    "\n",
    "# Check the shape\n",
    "print(augmented_tensor.shape)  # Should print torch.Size([60, 17, 16, 5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
